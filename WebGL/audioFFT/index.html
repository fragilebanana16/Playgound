<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Audio ShaderToy Style</title>
  <style>
    html, body { margin: 0; overflow: hidden; background: black; }
    canvas { display: block; width: 100vw; height: 100vh; }
    #controls {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 10;
    }
    input, button {
      padding: 6px 12px;
      font-size: 14px;
      margin-right: 6px;
    }
  </style>
</head>
<body>
  <div id="controls">
    <input type="file" id="fileInput" accept="audio/*" />
    <button id="playBtn" disabled>▶️ Play</button>
  </div>
  <canvas id="glcanvas"></canvas>

  <script>
    const canvas = document.getElementById('glcanvas');
    const gl = canvas.getContext('webgl');
    canvas.width = 800;
    canvas.height = 800;
    gl.viewport(0, 0, 800, 800);
    // Vertex shader
    const vsSource = `
      attribute vec2 aPos;
      varying vec2 vFragCoord;
      void main() {
        gl_Position = vec4(aPos, 0.0, 1.0);
        vFragCoord = (aPos * 0.5 + 0.5) * vec2(${canvas.width}.0, ${canvas.height}.0);
      }
    `;

    // Fragment shader (ShaderToy style)
    const fsSource = `
      precision mediump float;
      uniform vec3 iResolution;
      uniform float iTime;
      uniform sampler2D iChannel0;
      varying vec2 vFragCoord;

      vec3 B2_spline(vec3 x) {
          vec3 t = 3.0 * x;
          vec3 b0 = step(0.0, t)     * step(0.0, 1.0-t);
          vec3 b1 = step(0.0, t-1.0) * step(0.0, 2.0-t);
          vec3 b2 = step(0.0, t-2.0) * step(0.0, 3.0-t);
          return 0.5 * (
              b0 * pow(t, vec3(2.0)) +
              b1 * (-2.0*pow(t, vec3(2.0)) + 6.0*t - 3.0) + 
              b2 * pow(3.0-t,vec3(2.0))
          );
      }

      vec4 mainImage(vec2 fragCoord) {
          vec2 uv = fragCoord.xy / iResolution.xy;
		  uv.y -= 0.16;
          float fVBars = 100.0;
          float fHSpacing = 1.00;
          float fHFreq = (uv.x * 3.14);
          float squarewave = sign(sin(fHFreq*fVBars)+1.0-fHSpacing);

          float x = floor(uv.x * fVBars)/fVBars;
          float fSample = texture2D(iChannel0, vec2(abs(2.0 * x - 1.0), 0.25)).x;
          float fft = squarewave * fSample * 0.4;

          float fHBars = 100.0;
          float fVSpacing = 0.180;
          float fVFreq = (uv.y * 3.14);
          fVFreq = sign(sin(fVFreq * fHBars)+1.0-fVSpacing);

          vec2 centered = vec2(1.0) * uv - vec2(1.0);
          float t = iTime / 100.0;
          float polychrome = 1.0;
          vec3 spline_args = fract(vec3(polychrome*uv.x - t) + vec3(0.0, -1.0/3.0, -2.0/3.0));
          vec3 spline = B2_spline(spline_args);

          float f = abs(centered.y);
          vec3 base_color  = vec3(1.0, 1.0, 1.0) - f * spline;
          vec3 flame_color = pow(base_color, vec3(3.0));

          float tt = 0.3 - uv.y;
          float df = sign(tt);
          df = (df + 1.0) / 0.5;
          vec3 col = flame_color * vec3(1.0 - step(fft, abs(0.3 - uv.y))) * vec3(fVFreq);
          col -= col * df * 0.180;

          return vec4(col, 1.0);
      }

      void main() {
          gl_FragColor = mainImage(vFragCoord);
      }
    `;

    function createShader(gl, type, source) {
      const shader = gl.createShader(type);
      gl.shaderSource(shader, source);
      gl.compileShader(shader);
      return shader;
    }

    function createProgram(gl, vs, fs) {
      const program = gl.createProgram();
      gl.attachShader(program, vs);
      gl.attachShader(program, fs);
      gl.linkProgram(program);
      return program;
    }

    const vertexShader = createShader(gl, gl.VERTEX_SHADER, vsSource);
    const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fsSource);
    const program = createProgram(gl, vertexShader, fragmentShader);
    gl.useProgram(program);

    const positionBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    const positions = new Float32Array([
      -1, -1,
       1, -1,
      -1,  1,
       1,  1,
    ]);
    gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);

    const aPos = gl.getAttribLocation(program, 'aPos');
    gl.enableVertexAttribArray(aPos);
    gl.vertexAttribPointer(aPos, 2, gl.FLOAT, false, 0, 0);

    const iResolution = gl.getUniformLocation(program, 'iResolution');
    const iTime = gl.getUniformLocation(program, 'iTime');
    const iChannel0 = gl.getUniformLocation(program, 'iChannel0');

    gl.uniform3f(iResolution, canvas.width, canvas.height, 1.0);

    const audioTexture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, audioTexture);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, audioTexture);
    gl.uniform1i(iChannel0, 0);

    let analyser, dataArray, audioCtx, audio;

    document.getElementById('fileInput').addEventListener('change', (e) => {
      const file = e.target.files[0];
      if (!file) return;

      if (!audioCtx) {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      }

      audio = new Audio();
      audio.src = URL.createObjectURL(file);
      audio.loop = true;

      const source = audioCtx.createMediaElementSource(audio);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      source.connect(analyser);
      analyser.connect(audioCtx.destination);

      document.getElementById('playBtn').disabled = false;
    });

    document.getElementById('playBtn').addEventListener('click', () => {
      if (audioCtx && audio) {
        audioCtx.resume();
        audio.play();
      }
    });

    let startTime = performance.now();

    function render() {
      const time = (performance.now() - startTime) * 0.001;
      gl.uniform1f(iTime, time);

      if (analyser && dataArray) {
        analyser.getByteFrequencyData(dataArray);
        gl.bindTexture(gl.TEXTURE_2D, audioTexture);
        gl.texImage2D(
          gl.TEXTURE_2D,
          0,
          gl.LUMINANCE,
          dataArray.length,
          1,
          0,
          gl.LUMINANCE,
          gl.UNSIGNED_BYTE,
          dataArray
        );
      }

      gl.clear(gl.COLOR_BUFFER_BIT);
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
      requestAnimationFrame(render);
    }

    render();
  </script>
</body>
</html>
